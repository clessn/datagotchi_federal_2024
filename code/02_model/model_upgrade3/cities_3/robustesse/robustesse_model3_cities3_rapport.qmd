---
title: "Analyse de robustesse du modèle de prédiction avec 6 régions et 3 grandes villes"
author: "Équipe CLESSN"
date: "`r format(Sys.Date(), '%d %B %Y')`"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
  pdf:
    toc: true
    toc-depth: 3
    number-sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggplot2)
```

# Introduction

Ce document présente une analyse approfondie de la robustesse du modèle de prédiction électorale pour les élections fédérales canadiennes 2025. Ce modèle intègre:

- Des prédictions basées sur les codes postaux (RTA - Forward Sortation Areas)
- Des modèles spécifiques pour 6 régions du Canada (Ontario, Québec, Colombie-Britannique, Prairies, Atlantique, Territoires)
- Des modèles spécifiques pour 3 grandes villes (Montréal, Toronto, Vancouver)

L'extension du modèle aux grandes villes vise à améliorer la précision des prédictions dans les centres urbains qui présentent des dynamiques électorales distinctes des régions géographiques plus larges.

# Méthodologie

L'analyse de robustesse comprend plusieurs dimensions:

1. **Performance globale**: Accuracy, F1-score et autres métriques de performance
2. **Stabilité**: Résistance aux variations d'échantillonnage via bootstrap
3. **Équité géographique**: Performances comparées entre régions et villes
4. **Calibration**: Adéquation entre probabilités prédites et fréquences observées
5. **Comparaison**: Analyse comparative avec le modèle sans variables de villes

# Données d'évaluation

L'analyse est basée sur un ensemble de validation comprenant 17,555 observations, avec la distribution suivante:

```{r data_distribution, echo=FALSE}
vote_table <- data.frame(
  Parti = c("bq", "cpc", "lpc", "ndp", "gpc"),
  Application = c(4194, 4244, 5683, 2821, 348),
  Pilote = c(39, 97, 66, 52, 11)
)

kable(vote_table, 
      col.names = c("Parti", "Application", "Pilote"),
      caption = "Distribution des votes dans l'ensemble de validation") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Distribution des villes
city_summary <- data.frame(
  City = c("Montréal", "Toronto", "Vancouver"),
  Count = c(2143, 916, 302),
  Percentage = c(12.21, 5.22, 1.72)
)

kable(city_summary, 
      col.names = c("Ville", "Nombre d'observations", "Pourcentage (%)"),
      caption = "Distribution des grandes villes dans l'ensemble de validation") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Performance globale

## Métriques principales

```{r global_metrics, echo=FALSE}
# Métriques globales
global_metrics <- data.frame(
  Metric = c("Accuracy globale", "Accuracy premier ou deuxième choix", "Recall moyen (macro)", "Recall pondéré (weighted)"),
  Value = c(0.5439, 0.8291, 0.4524, 0.5439)
)

kable(global_metrics, 
      col.names = c("Métrique", "Valeur"),
      digits = 4,
      caption = "Métriques globales de performance") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Performance par parti

```{r party_metrics, echo=FALSE}
# Métriques par parti
party_metrics <- data.frame(
  Party = c("bq", "cpc", "lpc", "ndp", "gpc"),
  Precision = c(0.5430, 0.5669, 0.5185, 0.5629, 0.4483),
  Recall = c(0.8275, 0.5096, 0.4406, 0.4483, 0.0362),
  F1_Score = c(0.6557, 0.5367, 0.4764, 0.4991, 0.0670),
  Support = c(4233, 4341, 5749, 2873, 359),
  Top2_Accuracy = c(0.9608, 0.7754, 0.9019, 0.6638, 0.0808)
)

kable(party_metrics, 
      col.names = c("Parti", "Précision", "Rappel", "F1-Score", "Support", "Top-2 Accuracy"),
      digits = 4,
      caption = "Métriques de performance par parti politique") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Matrice de confusion

```{r confusion_matrix, echo=FALSE}
# Matrice de confusion
confusion_matrix <- matrix(
  c(3503, 799, 1653, 427, 69, 
    213, 2212, 991, 410, 76, 
    383, 1097, 2533, 743, 129, 
    134, 231, 563, 1288, 72, 
    0, 2, 9, 5, 13),
  nrow = 5, byrow = TRUE,
  dimnames = list(c("bq", "cpc", "lpc", "ndp", "gpc"), c("bq", "cpc", "lpc", "ndp", "gpc"))
)

kable(confusion_matrix, 
      caption = "Matrice de confusion (Lignes: prédictions, Colonnes: valeurs réelles)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Performance par région et ville

## Performance par région

```{r region_performance, echo=FALSE}
# Métriques par région
region_metrics <- data.frame(
  Region = c("ontario", "quebec", "british_columbia", "prairie", "atlantic", "territories"),
  Observations = c(3899, 9760, 1187, 1906, 803, NA),
  Accuracy = c(0.5427, 0.5307, 0.5442, 0.5845, 0.6139, NA),
  Top2_Accuracy = c(0.8582, 0.8097, 0.8273, 0.8526, 0.8692, NA)
)

kable(region_metrics, 
      col.names = c("Région", "Observations", "Accuracy", "Top-2 Accuracy"),
      digits = 4,
      caption = "Performance par région") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Graphique de performance par région
region_metrics_filtered <- region_metrics %>% filter(!is.na(Accuracy))
ggplot(region_metrics_filtered, aes(x = reorder(Region, Accuracy), y = Accuracy)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = sprintf("%.3f", Accuracy)), hjust = -0.1, size = 3.5) +
  coord_flip() +
  labs(x = "Région", y = "Accuracy", title = "Performance du modèle par région") +
  theme_minimal() +
  ylim(0, max(1, max(region_metrics_filtered$Accuracy) * 1.1))
```

## Performance par grande ville

```{r city_performance, echo=FALSE}
# Métriques par ville
city_metrics <- data.frame(
  City = c("Montréal", "Toronto", "Vancouver"),
  Observations = c(2143, 916, 302),
  Accuracy = c(0.5483, 0.5753, 0.5960),
  Top2_Accuracy = c(0.8339, 0.8657, 0.8477)
)

kable(city_metrics, 
      col.names = c("Ville", "Observations", "Accuracy", "Top-2 Accuracy"),
      digits = 4,
      caption = "Performance par grande ville") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Graphique de performance par ville
ggplot(city_metrics, aes(x = reorder(City, Accuracy), y = Accuracy)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  geom_text(aes(label = sprintf("%.3f", Accuracy)), hjust = -0.1, size = 3.5) +
  coord_flip() +
  labs(x = "Ville", y = "Accuracy", title = "Performance du modèle par grande ville") +
  theme_minimal() +
  ylim(0, max(1, max(city_metrics$Accuracy) * 1.1))
```

# Analyse de stabilité (Bootstrap)

L'analyse bootstrap permet d'évaluer la stabilité du modèle face à des variations d'échantillonnage.

```{r bootstrap, echo=FALSE}
# Résultats du bootstrap global
bootstrap_stats <- data.frame(
  Statistic = c("Accuracy moyenne", "Écart-type", "IC inférieur (95%)", "IC supérieur (95%)", "Coefficient de variation (%)"),
  Value = c(0.5068, 0.0184, 0.4666, 0.5435, 3.6306)
)

kable(bootstrap_stats, 
      col.names = c("Statistique", "Valeur"),
      digits = 4,
      caption = "Résultats de l'analyse bootstrap global (100 répétitions)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Bootstrap par ville
city_bootstrap <- data.frame(
  City = c("Montréal", "Toronto", "Vancouver"),
  Mean_Accuracy = c(0.5233, 0.5744, 0.5979),
  Std_Dev = c(0.0211, 0.0227, 0.0257),
  CI_Lower = c(0.4771, 0.5251, 0.5530),
  CI_Upper = c(0.5680, 0.6189, 0.6556)
)

kable(city_bootstrap, 
      col.names = c("Ville", "Accuracy moyenne", "Écart-type", "IC inférieur (95%)", "IC supérieur (95%)"),
      digits = 4,
      caption = "Résultats bootstrap par ville") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Calibration du modèle

La calibration évalue l'adéquation entre les probabilités prédites par le modèle et les fréquences réellement observées pour chaque parti.

```{r calibration, echo=FALSE, eval=FALSE}
# Note: Cette section serait à remplir avec les données de calibration si nécessaire
```

# Comparaison avec le modèle sans variables de villes

Cette section compare les performances du modèle actuel (avec variables de grandes villes) au modèle précédent (modèle à 6 régions sans variables de villes).

```{r comparison, echo=FALSE}
# Comparaison des modèles
comparison_df <- data.frame(
  Metric = c("Accuracy globale", "Amélioration (%)"),
  Model_6_Regions = c(0.5475, NA),
  Model_6_Regions_3_Cities = c(0.5439, NA)
)
comparison_df$Improvement <- comparison_df$Model_6_Regions_3_Cities - comparison_df$Model_6_Regions
comparison_df$Improvement_Percent <- (comparison_df$Improvement / comparison_df$Model_6_Regions) * 100

kable(comparison_df, 
      col.names = c("Métrique", "Modèle 6 régions", "Modèle 6 régions + 3 villes", "Différence", "Différence (%)"),
      digits = 4,
      caption = "Comparaison des performances entre modèles") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Visualisation de la comparaison
model_comparison <- data.frame(
  Model = c("Modèle 6 régions", "Modèle 6 régions + 3 villes"),
  Accuracy = c(0.5475, 0.5439)
)

ggplot(model_comparison, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.4f", Accuracy)), vjust = -0.5, size = 4) +
  labs(x = "", y = "Accuracy", title = "Comparaison des performances entre modèles") +
  theme_minimal() +
  ylim(0, 0.7) +
  theme(legend.position = "none")
```

# Résultats spécifiques aux villes

```{r city_comparison, echo=FALSE}
# Comparaison entre villes et hors villes
city_comparison <- data.frame(
  City = c("Montréal", "Hors Montréal", "Toronto", "Hors Toronto", "Vancouver", "Hors Vancouver"),
  Accuracy = c(0.5483, 0.5433, 0.5753, 0.5422, 0.5960, 0.5430),
  Top2_Accuracy = c(0.8339, 0.8284, 0.8657, 0.8270, 0.8477, 0.8287)
)

kable(city_comparison, 
      col.names = c("Zone", "Accuracy", "Top-2 Accuracy"),
      digits = 4,
      caption = "Comparaison des performances en zone urbaine vs non-urbaine") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Graphique de comparaison ville vs hors ville
city_comparison_reshaped <- data.frame(
  Zone = rep(c("Montréal", "Toronto", "Vancouver"), each = 2),
  Type = rep(c("Ville", "Hors ville"), 3),
  Accuracy = c(0.5483, 0.5433, 0.5753, 0.5422, 0.5960, 0.5430)
)

ggplot(city_comparison_reshaped, aes(x = Zone, y = Accuracy, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.3f", Accuracy)), 
            position = position_dodge(width = 0.9), vjust = -0.5, size = 3.5) +
  labs(x = "", y = "Accuracy", title = "Performance en zone urbaine vs non-urbaine") +
  theme_minimal() +
  ylim(0, 0.7) +
  scale_fill_brewer(palette = "Paired")
```

# Conclusion et recommandations

Sur la base de cette analyse de robustesse, nous pouvons tirer les conclusions suivantes:

1. **Performance globale**: Le modèle avec variables de grandes villes présente une légère diminution de performance (-0.66%) par rapport au modèle à 6 régions sans variables de villes. L'accuracy globale est de 54.39%, avec une accuracy du premier ou deuxième choix atteignant 82.91%.

2. **Performance différenciée par ville**:
   - Vancouver présente la meilleure performance (59.60% d'accuracy)
   - Toronto arrive en deuxième position (57.53%)
   - Montréal montre la performance la plus faible des trois villes (54.83%)
   - Chaque ville surpasse les performances dans les zones extérieures correspondantes

3. **Stabilité**: L'analyse bootstrap indique une bonne stabilité du modèle, avec un coefficient de variation de 3.63%. Les intervalles de confiance à 95% par ville montrent des plages acceptables, en particulier pour Vancouver.

4. **Limites**: 
   - Le modèle présente des performances très faibles pour le Parti vert (GPC) avec seulement 3.62% de rappel
   - L'ajout des variables de villes n'améliore pas la performance globale

## Recommandations

1. **Utilisation recommandée**:
   - Bien que le modèle global n'améliore pas les performances, il permet une meilleure prédiction dans les grandes villes
   - Utiliser ce modèle spécifiquement pour les zones urbaines, où il surpasse le modèle régional standard

2. **Améliorations futures**:
   - Explorer d'autres définitions des zones urbaines que les trois premières lettres des codes postaux
   - Envisager l'ajout d'autres grandes villes canadiennes (Calgary, Edmonton, etc.)
   - Augmenter l'échantillon pour améliorer la performance sur les petits partis

3. **Rapports de prédiction**:
   - Inclure systématiquement le deuxième choix prédit, étant donné l'accuracy élevée (82.91%) lorsqu'on considère les deux premiers choix

Ce modèle présente donc un intérêt particulier pour les prédictions ciblées en zones urbaines, mais n'est pas recommandé comme remplacement complet du modèle à 6 régions pour les prédictions à l'échelle nationale.