---
title: "Cluster Datagotchi"
subtitle: "Données du pilot1-2021"
lang: fr
format: 
  pdf:
    documentclass: article
    toc: true
    number-sections: true
    toc-depth: 2
    number-depth: 3
    mainfont: "DejaVu Serif"
    sansfont: "DejaVu Sans"
    monofont: "DejaVu Sans Mono"
    fontsize: 11pt
    geometry: [left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]
---

# Définir le nombre de clusters


## PCA et sélection des variables

Pour déterminer quelles variables sont les moins pertinentes à conserver à partir des résultats de l'analyse en composantes principales (PCA), nous pouvons examiner leurs coefficients dans les premiers axes principaux (PC1 à PC4). Les variables ayant des coefficients proches de zéro pour ces axes peuvent être considérées comme faiblement contributives à la variance des données globales. En général, on garde les variables ayant des coefficients élevés (en valeur absolue) sur au moins un des premiers axes, car cela signifie qu'elles expliquent une part significative de la variance.

```{r pca-graph1, echo=FALSE, fig.width=7, fig.height=5, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(factoextra)
library(tidyr)
library(ggcorrplot)

# Charger les données
df_pilot_2021_merged <- read.csv("/home/alexab/Dropbox/Ulaval/CLESSN/datagotchi_federal_2024/_SharedFolder_datagotchi_federal_2024/clustering/data/pilot2021_merged_clustering.csv")
data_filtered <- df_pilot_2021_merged %>%
  select(-c(X, source)) %>%
  drop_na()

# Appliquer la PCA
pca_result0 <- prcomp(
  data_filtered,
  scale = TRUE
)

summary(pca_result0)
### Environ 3-4 composantes font l'affaire

pca_result0$rotation[,1:4]

fviz_eig(pca_result0, addlabels = TRUE)


```

Les résultats de l'analyse en composantes principales montrent la variance expliquée par chaque axe. Dans ce cas, nous choisissons de retenir les quatre premiers axes, qui expliquent la majorité de la variance dans les données.

### Contribution des variables et corrélation
Les variables ayant des coefficients élevés sur ces axes sont les plus importantes pour expliquer la variance des données. Par exemple, les variables qui ont une forte contribution dans le premier ou deuxième axe doivent être retenues, tandis que celles avec une faible contribution sur les premiers axes peuvent être considérées comme moins pertinentes.
```{r pca-graph2, echo=FALSE, fig.width=12, fig.height=8, dpi=300, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
library(dplyr)
library(ggplot2)
library(cluster)
library(factoextra)
library(tidyr)
library(ggcorrplot)
library(tibble)
library(gridExtra)

df_pilot_2021_merged <- read.csv("/home/alexab/Dropbox/Ulaval/CLESSN/datagotchi_federal_2024/_SharedFolder_datagotchi_federal_2024/clustering/data/pilot2021_merged_clustering.csv")

groupes_variables <- list(
  transport = c("act_transport_Car", "act_transport_SUV", "act_transport_Moto", 
                "act_transport_Walk", "act_transport_Bicycle", 
                "act_transport_PublicTransportation", "act_transport_Taxi"),
  demographie1 = c("age34m", "age3554", "age55p", "male", "female", "ses_genderOther", 
                   "ses_hetero", "ses_gai", "ses_bisex"),
  demographie2 = c("langFr", "langEn", "ses_languageOther", "incomeLow", "incomeHigh", 
                   "immigrant", "educBHS", "educUniv"),
  activites = c("act_VisitsMuseumsGaleries", "act_Fishing", "act_Hunting", 
                "act_MotorizedOutdoorActivities", "act_Volunteering", 
                "act_Walk", "act_Gym", "act_TeamSport", "act_Run", 
                "act_Yoga", "act_None", "act_Other"),
  apparence = c("app_swag_Formel", "app_swag_Classique", "app_swag_Casual", 
                "app_swag_Sport", "app_swag_Chic", "app_swag_VintageHippBoheme", 
                "app_swag_Other", "app_swag_Rock", "app_noTattoo"),
  cons_brand = c("cons_brand_MaR", "cons_brand_BInd", "cons_brand_OnlineOnly", 
                 "cons_brand_ChainesB", "cons_brand_GSurf", "cons_brand_Frip", 
                 "cons_brand_Other"),
  cons_coffee = c("cons_coffee_place_noCoffee", "cons_coffee_TimH", "cons_coffee_Other", 
                  "cons_coffee_Starbucks", "cons_coffee_SC", "cons_coffee_McDo", 
                  "cons_coffee_place_ind"),
  cons_food = c("cons_Meat", "cons_Vege", "cons_Vegan"),
  habitat = c("ses_dwelling_app", "ses_dwelling_loft", "ses_dwelling_condo", 
              "ses_dwelling_tour", "ses_dwelling_detachedHouse", 
              "ses_dwelling_semiDetached", 
              "ses_dwelling_coop", "ses_dwelling_HLM", "ses_dwelling_mobile", 
              "ses_dwelling_other"),
  cons_alcool = c("cons_noDrink", "cons_redWineDrink", "cons_whiteWineDrink", 
                  "cons_roseDrink", "cons_sparklingDrink", "cons_regBeers", 
                  "cons_microBeers", "cons_spiritDrink", "cons_cocktailsDrink"),
  cons_tabac = c("cons_Smoke", "cons_SmokeStopping", "cons_SmokeStopped", 
                 "cons_SmokeNever", "cons_VapeNation")
)

data_filtered <- df_pilot_2021_merged %>%
  select(-c(X, source)) %>%
  drop_na()

pca_all <- prcomp(data_filtered, scale. = TRUE)
var_contrib <- factoextra::get_pca_var(pca_all)$contrib
variance_explained <- factoextra::get_eigenvalue(pca_all)$variance.percent

num_axes <- 4
all_contrib <- data.frame()

for (group_name in names(groupes_variables)) {
  vars_in_group <- groupes_variables[[group_name]]
  vars_present <- vars_in_group[vars_in_group %in% rownames(var_contrib)]
  if (length(vars_present) == 0) next
  
  contrib_group <- var_contrib[vars_present, 1:num_axes, drop = FALSE]

  for (i in 1:num_axes) {
    contrib_group[, i] <- contrib_group[, i] * (variance_explained[i] / 100)
  }
  
  df_contrib <- as.data.frame(contrib_group)
  df_contrib$Variable <- rownames(df_contrib)
  df_contrib$Group <- group_name  

  df_contrib <- df_contrib %>%
    pivot_longer(cols = starts_with("Dim"), names_to = "Axe", values_to = "Contribution") %>%
    group_by(Group, Variable) %>%
    summarise(TotalContributionWeighted = sum(Contribution), .groups = "drop")
  
  all_contrib <- bind_rows(all_contrib, df_contrib)
}

ggplot(all_contrib, aes(x = reorder(Variable, -TotalContributionWeighted), y = TotalContributionWeighted, fill = Group)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  facet_wrap(~ Group, scales = "free_y") +
  labs(title = "Contributions pondérées des variables aux axes",
       x = "Variables", y = "Contribution pondérée (%)") +
  theme_minimal() +
  theme(legend.position = "bottom", axis.text.y = element_text(size = 7))

```

```{r pca-graph3, echo=FALSE, fig.width=12, fig.height=8, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
library(dplyr)
library(ggplot2)
library(factoextra)
library(tidyr)
library(tibble)

# Supposons que vous avez déjà exécuté le code précédent et que `all_contrib` est disponible.

# Création de all_contrib_dodge
all_contrib_dodge <- data.frame()
for (group_name in names(groupes_variables)) {
  vars_in_group <- groupes_variables[[group_name]]
  vars_present <- vars_in_group[vars_in_group %in% rownames(var_contrib)]
  if (length(vars_present) == 0) next
  
  contrib_group <- var_contrib[vars_present, 1:num_axes, drop = FALSE]
  
  df_contrib <- as.data.frame(contrib_group)
  df_contrib$Variable <- rownames(df_contrib)
  df_contrib$Group <- group_name
  
  df_contrib <- df_contrib %>%
    pivot_longer(cols = starts_with("Dim"), names_to = "Axe", values_to = "Contribution")
  
  all_contrib_dodge <- bind_rows(all_contrib_dodge, df_contrib)
}

# Fusionner les contributions totales pondérées avec all_contrib_dodge
all_contrib_dodge <- all_contrib_dodge %>%
  left_join(all_contrib %>% select(Variable, TotalContributionWeighted), by = "Variable")

# Reordonner les variables en fonction de la contribution totale pondérée
all_contrib_dodge$Variable <- factor(all_contrib_dodge$Variable,
                                     levels = all_contrib_dodge %>%
                                       distinct(Variable, TotalContributionWeighted) %>%
                                       arrange(TotalContributionWeighted) %>%
                                       pull(Variable))

# Créer le graphique avec les variables reclassées
ggplot(all_contrib_dodge, aes(x = Variable, y = Contribution, fill = Axe)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ Group, scales = "free_y") +
  labs(title = "Contributions des variables par axe",
       x = "Variables", y = "Contribution (%)") +
  scale_fill_brewer(palette = "Set2", name = "Axes principaux") +
  theme_minimal() +
  theme(legend.position = "bottom", axis.text.y = element_text(size = 7))

```

```{r corr-graph1, echo=FALSE, fig.width=20, fig.height=16, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}

## corr_matrix
cor_matrix <- cor(x = data_filtered)

# Transformer la matrice en un format long (tidy)
cor_df <- as.data.frame(as.table(cor_matrix)) %>%
  rename(Variable1 = Var1, Variable2 = Var2, Correlation = Freq)

ggcorrplot::ggcorrplot(
  cor_matrix,
  method = "circle",
  hc.order = TRUE,
  type = "upper",
  outline.color = "#00000000",
  colors = c("#d4206b", "#ececec", "#20d48f")
)


```

```{r corr-graph2, echo=FALSE, fig.width=20, fig.height=16, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
knitr::include_graphics("/home/alexab/Dropbox/Ulaval/CLESSN/datagotchi_federal_2024/_SharedFolder_datagotchi_federal_2024/clustering/graph/tableau_corr.png")

```

## Variables sélectionnées
### Sélection variables activité
**act_VisitsMuseumsGaleries**, **act_Volunteering**, **act_Yoga**, **act_Run**, **act_Gym** ont des contributions intéressantes à au moins 1 des 4 dimensions et ne sont pas corrélées entre-elles.

**act_MotorizedOutdoorActivities**, **act_Fishing**, et **act_Hunting** ont de très bonnes contributions mais sont corrélées entre-elles. **act_MotorizedOutdoorActivities** est conservée car elle a la plus grande contribution pondérée.

### Sélection variables apparence
**app_noTattoo**, **app_swag_Casual** et **app_swag_VintageHippBoheme** 

### Sélection variables cons_alcool
**cons_regBeers**, **cons_cocktailsDrink**, **cons_microBeers**, **cons_redWineDrink**, **cons_noDrink** 

### Sélection variables cons_brand
**cons_brand_ChainesB**, **cons_brand_GSurf**, **cons_brand_MaR**, **cons_brand_Frip**

### Sélection variables cons_coffee
**cons_coffee_Starbucks** **cons_coffee_place_noCoffee** et **cons_coffee_TimH** sont sélectionnées

### Sélection variables cons_food
**cons_Meat**  et **cons_Vege** sont sélectionnées.

### Sélection variables cons_tabac
**cons_SmokeNever** est sélectionnée, était corrélée avec **cons_SmokeStopped**
**cons_Smoke** aussi sélectionnée car pas corrélée?

### Sélection variables demographie
**immigrant** et **educUniv** sont sélectionnées

**age34m** et **age55p** sont sélectionnées, 

**male** et **female** sont parfaitement corrélées, **male** a une contribution légèrement suppérieure

**ses_hetero**, **ses_gai**, **ses_bisex** sont sélectionnées

**langFr**, **langEN** et **ses_languageOther** sont sélectionnées

**incomeLow** et **incomeHigh** sont sélectionnées 

### Sélection variables habitat
**ses_dwelling_condo**, **ses_dwelling_app** et **ses_dwelling_detachedHouse** sont sélectionnées

### Sélection variables transport
**act_transport_PublicTransportation**, **act_transport_Walk** et **act_transport_Car** sont sélectionnées

## PCA sur variables sélectionnées
```{r pcaSelect-graph1, echo=FALSE, fig.width=12, fig.height=8, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
# Variables sélectionnées selon contrib et correlation -------------------

data_select <- df_pilot_2021_merged %>%
  select(
    act_VisitsMuseumsGaleries, act_Volunteering, act_Yoga, act_Run, act_Gym, act_MotorizedOutdoorActivities, act_None,
    app_noTattoo, app_swag_Casual, app_swag_VintageHippBoheme,
    cons_regBeers, cons_cocktailsDrink, cons_microBeers, cons_redWineDrink, cons_noDrink,
    cons_brand_ChainesB, cons_brand_GSurf, cons_brand_MaR, cons_brand_Frip,
    cons_coffee_Starbucks, cons_coffee_place_noCoffee, cons_coffee_TimH,
    cons_Meat, cons_Vege,
    cons_SmokeNever, cons_Smoke,
    immigrant, 
    educUniv, educBHS,
    age55p, age34m,
    male,
    ses_hetero, ses_gai,
    langEn, langFr, ses_languageOther,
    incomeHigh, incomeLow,
    ses_dwelling_condo, ses_dwelling_detachedHouse, ses_dwelling_app,
    act_transport_PublicTransportation, act_transport_Car, act_transport_Walk
  ) %>%
  drop_na()

# PCA --------------------------------------------------------------------

pca_result <- prcomp(
  data_select,
  scale = TRUE
)

summary(pca_result)
### Environ 3-4 composantes font l'affaire

pca_result$rotation[,1:4]

fviz_eig(pca_result, addlabels = TRUE)


```

## Méthode du coude
```{r cluster-graph1, echo=FALSE, fig.width=12, fig.height=8, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
# Clustering -------------------------------------------------------------

## Normalisation des données (optionnelle, recommandé pour k-means)
data_scaled <- scale(data_select)


### Coude
wss <- sapply(2:15, function(k){
  kmeans(data_scaled, centers = k, nstart = 25)$tot.withinss
})

# Tracer la courbe du coude
plot(2:15, wss, type = "b", pch = 19, frame = FALSE, 
     xlab = "Nombre de clusters K",
     ylab = "Somme des carrés intra-cluster (withinss)",
     main = "Méthode du coude pour déterminer K")

```

## Silhouette

```{r cluster-graph2, echo=FALSE, fig.width=12, fig.height=8, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
# Calculer l'indice de silhouette pour différents k
sil_width <- sapply(2:15, function(k){
  km.res <- kmeans(data_scaled, centers = k, nstart = 25)
  ss <- cluster::silhouette(km.res$cluster, dist(data_scaled))
  mean(ss[, 3])
})

# Tracer la courbe de l'indice de silhouette
plot(2:15, sil_width, type = "b", pch = 19, frame = FALSE,
     xlab = "Nombre de clusters K",
     ylab = "Largeur moyenne de la silhouette",
     main = "Indice de silhouette pour déterminer K")
```

```{r cluster-graph3, echo=FALSE, fig.width=12, fig.height=8, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
wss_scaled <- (wss - min(wss)) / (max(wss) - min(wss))
sil_width_scaled <- (sil_width - min(sil_width)) / (max(sil_width) - min(sil_width))

wss_scaled_rev <- rev(wss_scaled)
sil_sum <- wss_scaled_rev + sil_width_scaled

plot(2:15, sil_sum, type = "b")
```


## Nombre de cluster

```{r cluster-graph4, echo=FALSE, fig.width=20, fig.height=16, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}

for (i in c(3, 4, 5, 6, 7, 8, 9, 10, 12)){
  # Appliquer k-means avec un nombre de clusters k (à définir, ici k = 3)
  set.seed(123)  # Pour rendre les résultats reproductibles
  kmeans_result <- kmeans(data_scaled, centers = i, nstart = 25)
  # Ajouter les clusters aux données d'origine
  data_select[[paste0("cluster_", i)]] <- kmeans_result$cluster
}
 #Calcul de la distance (ici, distance euclidienne)
distance_matrix <- dist(data_scaled)

# MDS pour réduction à 2 dimensions
mds_result <- cmdscale(distance_matrix, k = 2)

# Ajouter les coordonnées MDS aux données
data_select$MDS1 <- mds_result[,1]
data_select$MDS2 <- mds_result[,2]

plot_data <- data_select |> 
  tidyr::pivot_longer(
    cols = starts_with("cluster_"),
    names_to = "n_clusters",
    values_to = "cluster",
    names_prefix = "cluster_"
  ) |> 
  mutate(n_clusters = as.numeric(n_clusters))

ggplot(plot_data, aes(x = MDS1, y = MDS2, color = factor(cluster))) +
  geom_point(alpha = 0.3) +
  clessnize::theme_clean_light() +
  facet_wrap(~n_clusters) +
  stat_ellipse()
```


## répondants par cluster

```{r cluster-graph5, echo=FALSE, fig.width=12, fig.height=8, message=FALSE, warning=FALSE, fig.landscape=TRUE, fig.fullwidth=TRUE}
# Charger les librairies nécessaires
# Charger les librairies nécessaires
library(dplyr)
library(knitr)
library(kableExtra)

# Obtenir le nombre de répondants par cluster pour chaque k
cluster_counts <- lapply(c(3, 4, 5, 6, 7, 8, 9, 10, 12), function(k) {
  # Calculer le tableau de fréquences pour chaque cluster
  table <- table(data_select[[paste0("cluster_", k)]])
  
  # Créer un vecteur avec toutes les positions de clusters pour k (1:k)
  all_clusters <- 1:max(c(12, k)) # Jusqu'à 12 car c'est le plus grand k
  
  # Remplir les clusters avec les valeurs ou une case vide
  sapply(all_clusters, function(cluster) {
    if (cluster %in% names(table)) {
      table[as.character(cluster)]
    } else if (cluster <= k) {
      0  # Si le cluster existe mais n'a pas de répondants
    } else {
      ""  # Laisser vide pour les clusters inexistants
    }
  })
})

# Transformer en data.frame avec les tailles de k comme rangées
summary_table <- do.call(rbind, cluster_counts)
rownames(summary_table) <- paste0("k = ", c(3, 4, 5, 6, 7, 8, 9, 10, 12))

# Convertir en data.frame pour affichage
summary_table <- as.data.frame(summary_table)

# Ajouter des noms de colonnes pour les clusters
colnames(summary_table) <- paste0("Cluster_", 1:ncol(summary_table))

# Afficher le tableau avec LaTeX-friendly options pour PDF
# Afficher le tableau avec `scale_down`
summary_table %>%
  kable(format = "latex", caption = "Nombre de répondants par cluster") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"), full_width = FALSE)

```

10 clusters

# Description des Clusters

## Cluster 1 : 

![](8cluster_1.png) 


## Cluster 2 : Jeunes hommes éduqués, amateurs de bières artisanales et de mode de vie actif

![](8cluster_2.png)

## Cluster 3 : Individus sobres, peu diplômés, et enclins à un style de vie simple

![](8cluster_3.png)

## Cluster 4 : Jeunes femmes au style vintage, actives culturellement et modérées dans leur consommation de viande

![](8cluster_4.png)

## Cluster 5 : Seniors traditionnels et consommateurs de vin rouge

![](8cluster_5.png)


## Cluster 6 : Hommes francophones amateurs de bière régulière

![](8cluster_6.png)

## Cluster 7 : Jeunes urbains adeptes des transports publics

![](8cluster_7.png)

## Cluster 8 : Femmes francophones, éduquées et consommatrices de cocktails

![](8cluster_8.png)

